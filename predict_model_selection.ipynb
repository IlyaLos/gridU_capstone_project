{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import tree, ensemble\n",
    "import random\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataframes\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "X_train = pd.read_csv('sel_X_train.csv')\n",
    "X_test = pd.read_csv('sel_X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unused ids \n",
    "train.drop('Unnamed: 0', 1, inplace=True)\n",
    "X_train.drop('Unnamed: 0', 1, inplace=True)\n",
    "X_test.drop('Unnamed: 0', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target value\n",
    "y_train = train['relevance'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test each model apply cross_val_score with 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.400616917194\n"
     ]
    }
   ],
   "source": [
    "# Linear model with l2 regularization\n",
    "print cross_val_score(linear_model.Ridge(), X_train, y_train, cv = 10, scoring = 'neg_mean_absolute_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.439455082754\n"
     ]
    }
   ],
   "source": [
    "# Linear model with l2 regularization\n",
    "print cross_val_score(linear_model.Lasso(), X_train, y_train, cv = 10, scoring = 'neg_mean_absolute_error').mean()\n",
    "\n",
    "# And all coef equals zero\n",
    "model = linear_model.Lasso()\n",
    "model.fit(X_train, y_train)\n",
    "print model.coef_\n",
    "# It's not good information about our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30 4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.392177182528\n30 5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.392283943338\n30 6"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391480924519\n30 7"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391309605325\n30 8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391110049812\n60 4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.392112932128\n60 5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.392097390841\n60 6"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391360791409\n60 7"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391237511277\n60 8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391020802139\n90 4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.392043171004\n90 5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.392069918684\n90 6"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391332805375\n90 7"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391214541906\n90 8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.39100038797\n120 4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.392036209499\n120 5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.392029344773\n120 6"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391313143197\n120 7"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.391212261501\n120 8"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.390996604063\n"
     ]
    }
   ],
   "source": [
    "# ensemble of decision trees\n",
    "for est_num in range(30, 130, 30):\n",
    "    for dep in range(4, 9, 1):\n",
    "        print est_num, dep, cross_val_score(ensemble.RandomForestRegressor(n_estimators = est_num, max_depth=dep, random_state=0), \n",
    "                                            X_train, y_train, cv = 10, scoring = 'neg_mean_absolute_error').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing number of tree decreases standard deviation, but much number of trees will slow down our model.\n",
    "Increasing max depth of trees leads to overfitting.\n",
    "\n",
    "Let's take number of trees equals 30 and max depth equals 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.391480924519\n"
     ]
    }
   ],
   "source": [
    "# ensemble of decision trees\n",
    "print cross_val_score(ensemble.RandomForestRegressor(n_estimators = 30, max_depth=6, random_state=0), \n",
    "                      X_train, y_train, cv=10, scoring = 'neg_mean_absolute_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.391419425963\n"
     ]
    }
   ],
   "source": [
    "# ensemble of random forests with bagging\n",
    "print cross_val_score(ensemble.BaggingRegressor(ensemble.RandomForestRegressor(n_estimators=30, max_depth=6, \n",
    "                                                                               random_state=0), 50, random_state=0), \n",
    "                      X_train, y_train, cv=10, scoring = 'neg_mean_absolute_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.388958385374\n"
     ]
    }
   ],
   "source": [
    "# final calculation and create output file with prediction\n",
    "random_forest = ensemble.RandomForestRegressor(n_estimators=30, max_depth=6, random_state=0)\n",
    "model = ensemble.BaggingRegressor(random_forest, 50, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# calc mean_absolute_error for train set\n",
    "res = 0\n",
    "data2 = model.predict(X_train)\n",
    "for i in range(len(data2)): # for linear models\n",
    "    data2[i] = min(max(1.0, data2[i]), 3.0)\n",
    "   \n",
    "for i in range(len(y_train)):\n",
    "    res += abs(y_train[i] - data2[i])\n",
    "\n",
    "print res / len(y_train)\n",
    "#\n",
    "\n",
    "data = model.predict(X_test)\n",
    "for i in range(len(data)): # for linear models\n",
    "    data[i] = min(max(1.0, data[i]), 3.0)\n",
    "\n",
    "output = pd.DataFrame({'id': test.id, 'relevance': data}).set_index('id')\n",
    "\n",
    "output.to_csv('output.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}